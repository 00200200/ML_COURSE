{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eF4QO1CrHDmP"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q9WAhJSCHgmK"},"outputs":[],"source":["  import pandas as pd\n","  house_df = pd.read_csv('drive/MyDrive/CL/Day_1/kc_house_data_preprocessed.csv')\n","  house_df.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wx6tkG6tIAzY"},"outputs":[],"source":["house_df.drop(['Unnamed: 0'],axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J40XHwH7IAxi"},"outputs":[],"source":["X = house_df.drop(['price'],axis=1)\n","y = house_df['price']\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aS8lDDABIAxB"},"outputs":[],"source":["x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"55z6kttjIArX"},"outputs":[],"source":["lambda_values = [0,0.01,0.1,1,10,100]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"rQHz_neUIAgz"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","  return fit_method(estimator, *args, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.970e+14, tolerance: 1.977e+11 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.696e+14, tolerance: 1.977e+11\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.696e+14, tolerance: 1.977e+11\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.696e+14, tolerance: 1.977e+11\n","  model = cd_fast.enet_coordinate_descent(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+14, tolerance: 1.977e+11\n","  model = cd_fast.enet_coordinate_descent(\n"]},{"name":"stdout","output_type":"stream","text":["100 43439929415.22531\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e+14, tolerance: 1.977e+11\n","  model = cd_fast.enet_coordinate_descent(\n"]}],"source":["from sklearn.linear_model import Lasso\n","best_res = 0\n","best_lambda = 0\n","from sklearn.metrics import r2_score,mean_squared_error\n","for lambda_value in lambda_values:\n","  lasso = Lasso(alpha=lambda_value,max_iter=12000)\n","  lasso.fit(x_train,y_train)\n","  y_pred = lasso.predict(x_test)\n","  mse = mean_squared_error(y_test,y_pred)\n","  # MSE Porownujemy\n","  if mse \u003e best_res:\n","    best_res = mse\n","    best_lambda = lambda_value\n","print(best_lambda, best_res)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3l9FmvQQK0GQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JaxgvvAGK1GT"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMLLiSIcAIQTY2529diMtZg","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}